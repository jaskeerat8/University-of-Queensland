{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://b2943a752d84:4040\n",
       "SparkContext available as 'sc' (version = 3.0.1, master = local[*], app id = local-1665705678241)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import scala.collection.mutable.Map\n",
       "import scala.collection.immutable.ListMap\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.collection.mutable.Map\n",
    "import scala.collection.immutable.ListMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verbs_all: org.apache.spark.rdd.RDD[String] = all_verbs.txt MapPartitionsRDD[1] at textFile at <console>:27\n",
       "shakespeare: org.apache.spark.rdd.RDD[String] = shakespeare.txt MapPartitionsRDD[3] at textFile at <console>:28\n",
       "verb_dict: org.apache.spark.rdd.RDD[String] = verb_dict.txt MapPartitionsRDD[5] at textFile at <console>:29\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val verbs_all = sc.textFile(\"all_verbs.txt\")\n",
    "val shakespeare = sc.textFile(\"shakespeare.txt\")\n",
    "val verb_dict = sc.textFile(\"verb_dict.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verb_list: Array[String] = Array(abash, abashed, abashed, abashes, abashing, abate, abated, abated, abates, abating, abide, abode, abode, abides, abiding, absorb, absorbed, absorbed, absorbs, absorbing, accept, accepted, accepted, accepts, accepting, accompany, accompanied, accompanied, accompanies, accompanying, ache, ached, ached, aches, aching, achieve, achieved, achieved, achieves, achieving, acquire, acquired, acquired, acquires, acquiring, act, acted, acted, acts, acting, add, added, added, adds, adding, address, addressed, addressed, addresses, addressing, adjust, adjusted, adjusted, adjusts, adjusting, admire, admired, admired, admires, admiring, admit, admitted, admitted, admits, admitting, advise, advised, advised, advises, advising, afford, afforded, afforded, affords, afford...\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val verb_list = verbs_all.map(_.trim()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shakespeare_pre: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[10] at map at <console>:29\n",
       "shakespeare_split: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[11] at flatMap at <console>:30\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Removing empty lines, punctuations & Changing capitalization\n",
    "val shakespeare_pre = shakespeare.filter(row => !row.isEmpty).map(_.replaceAll(\"[,.!?:;']\", \"\").replaceAll(\"\\\\[\", \"\").replaceAll(\"\\\\]\",\"\")).map(_.toLowerCase).map(_.trim())\n",
    "val shakespeare_split = shakespeare_pre.flatMap(line=>line.split(\"\\\\s+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shakespeare_verb_filter: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[12] at filter at <console>:31\n",
       "shakespeare_verb_count: scala.collection.Map[String,Long] = Map(purifies -> 1, breaks -> 29, forgotten -> 15, leer -> 5, respecting -> 4, lights -> 28, laughing -> 14, mew -> 5, beheld -> 26, looks -> 214, implored -> 1, blurs -> 1, scare -> 4, subscribes -> 3, shivers -> 2, coursing -> 2, tiring -> 4, used -> 19, eye -> 414, striking -> 10, allowed -> 4, sack -> 57, straining -> 4, murmur -> 3, severs -> 1, boil -> 6, writing -> 23, curbed -> 1, believing -> 5, lasting -> 13, conquers -> 3, cooled -> 2, misuses -> 1, warns -> 1, killed -> 7, concluding -> 1, cooks -> 3, rub -> 12, respects -> 18, regarding -> 1, beg -> 94, regarded -> 6, spelling -> 1, bow -> 47, succeed -> 13, ta...\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Getting only the verbs present inside verb list\n",
    "val shakespeare_verb_filter = shakespeare_split.filter(word => verb_list.contains(word))\n",
    "val shakespeare_verb_count = shakespeare_verb_filter.countByValue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verb_dict_map: Array[(String, String)] = Array((abash,abash), (abashed,abash), (abashes,abash), (abashing,abash), (abate,abate), (abated,abate), (abates,abate), (abating,abate), (abide,abide), (abode,abide), (abides,abide), (abiding,abide), (absorb,absorb), (absorbed,absorb), (absorbs,absorb), (absorbing,absorb), (accept,accept), (accepted,accept), (accepts,accept), (accepting,accept), (accompany,accompany), (accompanied,accompany), (accompanies,accompany), (accompanying,accompany), (ache,ache), (ached,ache), (aches,ache), (aching,ache), (achieve,achieve), (achieved,achieve), (achieves,achieve), (achieving,achieve), (acquire,acquire), (acquired,acquire), (acquires,acquire), (acquiring,acquire), (act,act), (acted,act), (acts,act), (acting,act), (add,add), (added,add), (adds,add), (adding...\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Making key value pair of verbs for mapping\n",
    "val verb_dict_map = verb_dict.map(line => line.split(\"\\n\")).map(arr => arr.head.split(\",\")).flatMap(arr => arr.map(word => (word, arr.head)).distinct).collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "final_verb_dict_map: scala.collection.mutable.Map[String,String] = Map(worried -> worry, follow -> follow, forlore -> forlese, digging -> dig, migrate -> migrate, preferred -> prefer, construed -> construe, forlorn -> forlese, inaugurate -> inaugurate, founding -> found, consorted -> consort, immersed -> immerse, handles -> handle, illustrating -> illustrate, detected -> detect, betraying -> betray, whipped -> whip, chooses -> choose, created -> create, forsakes -> forsake, shrink -> shrink, consults -> consult, satisfy -> satisfy, humiliates -> humiliate, hypnotize -> hypnotize, spent -> spend, gag -> gag, dances -> dance, contemned -> contemn, inscribes -> inscribe, questioned -> question, welcome -> welcome, absorbs -> absorb, costing -> cost, pasted -> paste, relates -> relate, seat...\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Getting first occurance of unique key in key-value pairs\n",
    "val final_verb_dict_map: Map[String,String] = Map.empty[String,String]\n",
    "\n",
    "for((key, value) <- verb_dict_map){\n",
    "    if(!final_verb_dict_map.contains(key)){\n",
    "        final_verb_dict_map += (key -> value)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_shakespeare_verb_count: List[(String, Long)] = List((purify,1), (break,29), (forget,15), (leer,5), (respect,4), (light,28), (laugh,14), (mew,5), (behold,26), (look,214), (implore,1), (blur,1), (scare,4), (subscribe,3), (shiver,2), (course,2), (tire,4), (use,19), (eye,414), (strike,10), (allow,4), (sack,57), (strain,4), (murmur,3), (sever,1), (boil,6), (write,23), (curb,1), (believe,5), (last,13), (conquer,3), (cool,2), (misuse,1), (warn,1), (kill,7), (conclude,1), (cook,3), (rub,12), (respect,18), (regard,1), (beg,94), (regard,6), (spell,1), (bow,47), (succeed,13), (taste,7), (want,21), (dwell,2), (kill,29), (measure,95), (pull,4), (empty,2), (roll,4), (chide,49), (propose,1), (notify,2), (contract,1), (hatch,1), (pardon,2), (enjoy,5), (please,388), (thrust,4), (clutch,3), (mind,61)...\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Getting occurance of verbs\n",
    "val new_shakespeare_verb_count = for{\n",
    "    \n",
    "    (key, value) <- shakespeare_verb_count.toList;\n",
    "    new_key <- final_verb_dict_map.get(key)\n",
    "\n",
    "} yield (new_key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result: scala.collection.immutable.Map[String,Long] = Map(leer -> 6, mew -> 6, scare -> 5, eye -> 1098, sack -> 61, murmur -> 7, boil -> 13, rub -> 19, beg -> 109, bow -> 62, succeed -> 25, measure -> 111, chide -> 86, notify -> 2, please -> 438, clutch -> 3, read -> 318, hurry -> 10, drive -> 76, tire -> 38, slit -> 1, find -> 802, shoot -> 84, spit -> 35, announce -> 1, contend -> 21, nurse -> 210, support -> 14, produce -> 20, question -> 166, chip -> 1, satisfy -> 78, smother -> 10, consult -> 6, scream -> 2, test -> 5, moult -> 1, feel -> 177, inlay -> 2, dye -> 8, grind -> 169, vanish -> 20, paint -> 90, reach -> 30, begin -> 246, lead -> 264, win -> 224, review -> 1, fail -> 76, recollect -> 1, spread -> 31, approve -> 44, saddle -> 10, prove -> 282, rid -> 32, verify -> 8, chall...\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Grouping by key value and getting final count\n",
    "val result = new_shakespeare_verb_count.groupBy(_._1).mapValues(seq => seq.map(_._2).reduce(_ + _))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result_top10: scala.collection.immutable.ListMap[String,Long] = ListMap(be -> 26661, have -> 7840, do -> 6396, come -> 3596, make -> 2888, go -> 2566, love -> 2479, let -> 2384, say -> 2336, know -> 2239)\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Ordering in Descending Values\n",
    "val result_top10 = ListMap(result.toSeq.sortWith(_._2 > _._2):_*).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(be,26661)\n",
      "(have,7840)\n",
      "(do,6396)\n",
      "(come,3596)\n",
      "(make,2888)\n",
      "(go,2566)\n",
      "(love,2479)\n",
      "(let,2384)\n",
      "(say,2336)\n",
      "(know,2239)\n"
     ]
    }
   ],
   "source": [
    "result_top10.foreach(println)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
