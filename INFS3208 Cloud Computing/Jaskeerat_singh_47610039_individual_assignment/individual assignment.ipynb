{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.stat import Correlation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "spark = SparkSession.builder.appName(\"IndividualAssignment\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_defined_schema = StructType() \\\n",
    "        .add(\"year\", IntegerType(), True) \\\n",
    "        .add(\"month\", IntegerType(), True) \\\n",
    "        .add(\"carrier\", StringType(), True) \\\n",
    "        .add(\"carrier_name\", StringType(), True) \\\n",
    "        .add(\"airport\", StringType(), True) \\\n",
    "        .add(\"airport_name\", StringType(), True) \\\n",
    "        .add(\"arr_flights\", IntegerType(), True) \\\n",
    "        .add(\"arr_del15\", IntegerType(), True) \\\n",
    "        .add(\"carrier_ct\", DoubleType(), True) \\\n",
    "        .add(\"weather_ct\", DoubleType(), True) \\\n",
    "        .add(\"nas_ct\", DoubleType(), True) \\\n",
    "        .add(\"security_ct\", DoubleType(), True) \\\n",
    "        .add(\"late_aircraft_ct\", DoubleType(), True) \\\n",
    "        .add(\"arr_cancelled\", IntegerType(), True) \\\n",
    "        .add(\"arr_diverted\", IntegerType(), True) \\\n",
    "        .add(\"arr_delay\", IntegerType(), True) \\\n",
    "        .add(\"carrier_delay\", IntegerType(), True) \\\n",
    "        .add(\"weather_delay\", IntegerType(), True) \\\n",
    "        .add(\"nas_delay\", IntegerType(), True) \\\n",
    "        .add(\"security_delay\", IntegerType(), True) \\\n",
    "        .add(\"late_aircraft_delay\", IntegerType(), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\") \\\n",
    "        .option(\"header\", True) \\\n",
    "        .option(\"quote\", \"\\\"\") \\\n",
    "        .option(\"escape\", \"\\\"\") \\\n",
    "        .option(\"nullValue\", \"null\") \\\n",
    "        .schema(user_defined_schema) \\\n",
    "        .load(\"hdfs://namenode:8020/datasets/Airline_Delay_Cause.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of the dataframe\n",
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Schema of the Dataframe\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Description of each column\n",
    "df.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trim and get cleaned airport_name\n",
    "df = df.withColumn(\"airport_name\", trim(element_at(split(col(\"airport_name\"), \":\"), -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Date Column\n",
    "df = df.withColumn('Date', concat_ws('-', df[\"year\"].cast(StringType()), df[\"month\"].cast(StringType())).cast('date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of Numerical columns\n",
    "list_of_numerical_columns = [i[0] for i in df.dtypes if i[1] not in [\"string\", \"date\"]]\n",
    "list_of_numerical_columns = list_of_numerical_columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding total_number_delays column\n",
    "df = df.withColumn('total_number_delays', df.carrier_ct + df.weather_ct + df.nas_ct + df.late_aircraft_ct)\n",
    "df = df.withColumn('total_number_delays', df[\"total_number_delays\"].cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Busy_type column based on arrival flights\n",
    "def busytypefunction(row):\n",
    "    value = temp_df[(temp_df[\"carrier\"] == row[\"carrier\"]) & (temp_df[\"year\"] == row[\"year\"])].reset_index()[\"arr_flights\"][0]\n",
    "    \n",
    "    if((value >= 0) and (value < 40000)):\n",
    "        busy_type = 0\n",
    "    elif((value >= 40000) and (value < 80000)):\n",
    "        busy_type = 1\n",
    "    elif(value >= 80000):\n",
    "        busy_type = 2\n",
    "    else:\n",
    "        busy_type = -1\n",
    "    \n",
    "    return busy_type\n",
    "\n",
    "temp_df = (df.toPandas().groupby([\"carrier\", \"year\"])[\"arr_flights\"].sum()/12).reset_index()\n",
    "temp_df[\"arr_flights\"] = temp_df[\"arr_flights\"].astype(int)\n",
    "\n",
    "temp_df[\"busy_type\"] = temp_df.apply(lambda row: busytypefunction(row), axis=1)\n",
    "temp_df = temp_df.drop(['arr_flights'], axis=1)\n",
    "temp_df = spark.createDataFrame(temp_df)\n",
    "df = df.join(temp_df, [\"carrier\", \"year\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing duplicate rows\n",
    "df = df.distinct()\n",
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Imputating Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count of Nulls in each column\n",
    "null_count = df.select(*(count(when(col(i).isNull(), i)).cast(\"string\").alias(i) for i in df.columns)).toPandas()\n",
    "\n",
    "#Percentage of Nulls in each column\n",
    "null_percent = df.select([(count(when(col(i).isNull(), i))/count(lit(1))*100).alias(i) for i in df.columns]).toPandas()\n",
    "\n",
    "null_df = null_count.append(null_percent)\n",
    "null_df.index = [\"Count\", \"Percentage\"]\n",
    "null_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Imputation of nulls in columns\n",
    "\n",
    "for i in df.dtypes:\n",
    "    if((i[1] != \"string\") and (i[1] != \"date\")):\n",
    "        mean_value = df.agg({i[0] : 'mean'}).collect()[0][0]\n",
    "        df = df.na.fill(int(mean_value), i[0])\n",
    "\n",
    "null_df = df.select(*(count(when(col(i).isNull(), i)).cast(\"string\").alias(i) for i in df.columns)).toPandas()\n",
    "null_df.index = [\"Count\"]\n",
    "null_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot for Outlier detection\n",
    "\n",
    "outlier_boxplot = df.toPandas().boxplot(column = list_of_numerical_columns, figsize=(15, 5))\n",
    "outlier_boxplot.plot()\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Removing outliers for the the numerical columns\n",
    "\n",
    "for i in [\"arr_delay\", \"carrier_delay\", \"nas_delay\", \"late_aircraft_delay\"]:\n",
    "    \n",
    "    percentile_range = df.approxQuantile(i, [0.25, 0.75], 0)\n",
    "    \n",
    "    iqr = percentile_range[1] - percentile_range[0]    \n",
    "    upper = percentile_range[1] + (iqr*1.5)\n",
    "    lower = percentile_range[0] - (iqr*1.5)\n",
    "    \n",
    "    print(i + \" :: upper: \" + str(upper) + \", lower: \" + str(lower))\n",
    "    df = df.filter(df[i].between(lower, upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Coorelation Matrix heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coorelation matrix\n",
    "corrMatrix = df[list_of_numerical_columns].toPandas().corr()\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(corrMatrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Queries using Spark SQL & Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registering dataframe as temptable\n",
    "df.registerTempTable(\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of delays in each year\n",
    "year_delays = spark.sql(\"select year, sum(total_number_delays) as number_of_delays from df group by year order by year\").toPandas()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(year_delays[\"year\"], year_delays[\"number_of_delays\"], linewidth = 2, color = \"#13b026\", marker = \"o\", markeredgecolor = \"#000000\")\n",
    "plt.xticks(year_delays[\"year\"])\n",
    "plt.xlabel(\"YEAR\", labelpad = 15)\n",
    "plt.ylabel(\"Number of Delays\", labelpad = 15)\n",
    "plt.title(\"Number of Delays for Each Year\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of average monthly delays for each carrier for year 2021\n",
    "monthly_delays = spark.sql(\"select carrier_name, round(sum(total_number_delays)/12, 4) as average_monthly_delays from df where year = 2021 group by carrier_name order by round(sum(total_number_delays)/12) desc\").toPandas()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.barplot(x = monthly_delays['carrier_name'], y = monthly_delays['average_monthly_delays'], edgecolor = \"#000000\", palette = 'Wistia_r')\n",
    "plt.title(\"Average Monthly Delays for each Airline\")\n",
    "plt.xlabel(\"Carrier\", labelpad = 15)\n",
    "plt.ylabel(\"Average Monthly Delays\", labelpad = 15)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of arriving flights, cancelled flights for each carrier in year 2021\n",
    "arrive_cancelled = spark.sql(\"select carrier_name, sum(arr_flights) as arriving_flights, sum(arr_cancelled) as cancelled_flights, round(sum(arr_cancelled)/sum(arr_flights), 4) as ratio from df where year >= 2021 group by carrier_name order by ratio\").toPandas()\n",
    "arrive_cancelled.index = arrive_cancelled[\"carrier_name\"]\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(15, 5))\n",
    "ax1.set_xlabel('Carriers')\n",
    "ax1.set_ylabel('Number of flights', labelpad = 20)\n",
    "ax1.bar(arrive_cancelled[\"carrier_name\"], arrive_cancelled[\"arriving_flights\"], edgecolor = \"#000000\", color = \"#2399fa\")\n",
    "\n",
    "ax2 = ax1.twinx()  \n",
    "ax2.set_ylabel(\"Number of cancelled flights\", labelpad = 20, rotation = 270)\n",
    "ax2.plot(arrive_cancelled[\"carrier_name\"], arrive_cancelled[\"cancelled_flights\"], linewidth = 2, color = \"#db0f1d\", marker = \"o\", markeredgecolor = \"#000000\")\n",
    "\n",
    "ax1.tick_params(labelrotation = 90)\n",
    "fig.legend([\"Number of Flights\", \"Number of Cancelled Flights\"])\n",
    "plt.title(\"Number of Flights to Number of Cancelled Flights\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of flights for each carrier\n",
    "carrier_flights = spark.sql(\"select carrier_name, sum(arr_flights) as number_of_flights from df where year >= 2021 group by carrier_name order by sum(arr_flights) desc\").toPandas()\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(y = carrier_flights['carrier_name'], x = carrier_flights['number_of_flights'], orient = \"h\", edgecolor = \"#000000\", palette = 'GnBu_r')\n",
    "plt.ylabel(\"Carrier\", labelpad = 15)\n",
    "plt.xlabel(\"Flights served\", labelpad = 15)\n",
    "\n",
    "for index, value in enumerate(carrier_flights[\"number_of_flights\"]):\n",
    "    plt.text(value, index, \"  \" + str(value))\n",
    "\n",
    "plt.title(\"Number of Flights for each Airline in year 2021-present\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ratio of delays to arrived flights\n",
    "ratio_arr_delay = spark.sql(\"select carrier_name, sum(arr_flights) as number_of_arriving_flights, sum(total_number_delays) as number_of_delays, round(sum(total_number_delays)/sum(arr_flights), 4) as ratio from df where year >= 2021 group by carrier_name order by round(sum(total_number_delays)/sum(arr_flights), 4)\").toPandas()\n",
    "\n",
    "ratio_arr_delay[[\"carrier_name\", \"number_of_arriving_flights\", \"number_of_delays\"]].plot(x = \"carrier_name\", kind='bar', stacked=True, edgecolor = \"#000000\", figsize=(15, 5))\n",
    "plt.xlabel(\"Carrier\", labelpad = 15)\n",
    "plt.ylabel(\"Count\", labelpad = 15)\n",
    "plt.title(\"Arranged in ascending ratio of delays to total arrivals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ratio of delays to delayed_upto_15min for each carrier\n",
    "spark.sql(\"select carrier_name, sum(arr_del15) as delayed_upto_15_min, sum(total_number_delays) as total_delays, round(sum(arr_del15)/sum(total_number_delays), 4) as ratio from df where year >= 2021 group by carrier_name order by round(sum(arr_del15)/sum(total_number_delays), 4) desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Average minutes of delay due to National Aviation System greater than 24 hours monthly\n",
    "nas_delay = spark.sql(\"select airport_name, round(round(sum(nas_delay)/12)/60) as average_monthly_hours from df where year >= 2021 group by airport_name order by round(sum(nas_delay)/12)\").toPandas()\n",
    "nas_delay = nas_delay[nas_delay[\"average_monthly_hours\"] > 24]\n",
    "\n",
    "nas_delay.plot.bar(x = 'airport_name', y = 'average_monthly_hours', mark_right = True, figsize=(15, 5), edgecolor = \"#000000\", color = \"#fc9403\")\n",
    "plt.ylabel(\"Average Monthly Hours\", labelpad = 15)\n",
    "plt.xlabel(\"Airport Name\", labelpad = 15)\n",
    "plt.title(\"Average Hours of Delay Monthly due to National Aviation Systems\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of flights cancelled for each carrier average monthly and total yearly\n",
    "yearly_cancelled = spark.sql(\"select year, carrier_name, sum(arr_cancelled) as cancelled_flights from df group by year, carrier_name order by year, carrier_name\").toPandas()\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for i in yearly_cancelled[\"carrier_name\"].unique():\n",
    "    yearly_cancelled_df = yearly_cancelled[yearly_cancelled[\"carrier_name\"] == i]\n",
    "    plt.plot(yearly_cancelled_df[\"year\"], yearly_cancelled_df[\"cancelled_flights\"], label = i, linewidth = 2)\n",
    "\n",
    "plt.legend(ncol=2)\n",
    "plt.xticks(yearly_cancelled[\"year\"].unique())\n",
    "plt.ylabel(\"Number of Cancelled Flights\", labelpad = 15)\n",
    "plt.xlabel(\"YEAR\", labelpad = 15)\n",
    "plt.title(\"Total Number of Cancelled Flights for each Airline Yearly\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average number of flights for each carrier every month\n",
    "average_flights = spark.sql(\"select carrier_name, month, cast(round(avg(arr_flights)) as int) as number_of_flights from df group by carrier_name, month order by carrier_name, month\").toPandas()\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for i in average_flights[\"carrier_name\"].unique():\n",
    "    average_flights_df = average_flights[average_flights[\"carrier_name\"] == i]\n",
    "    plt.plot(average_flights_df[\"month\"], average_flights_df[\"number_of_flights\"], label = i, linewidth = 2)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "plt.xticks(average_flights[\"month\"].unique())\n",
    "plt.ylabel(\"Average number of Flights every month\", labelpad = 15)\n",
    "plt.xlabel(\"Month\", labelpad = 15)\n",
    "plt.title(\"Average number of Flights each Month for each Airline\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most security breaches airports\n",
    "\n",
    "print(\"Top Airports with most security breaches:\")\n",
    "most_dangerous = spark.sql(\"select airport_name, round(sum(security_ct)/sum(arr_flights), 4) as ratio_of_security_breaches_to_flights from df group by airport_name order by round(sum(security_ct)/sum(arr_flights), 4) desc limit 15\").show()\n",
    "most_dangerous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yearly monthly security breaches\n",
    "security_breaches = spark.sql(\"select year, month, cast(concat_ws('-', year, month, 1)as date) as Date, cast(round(sum(security_ct)) as int) as count_of_security_breaches from df group by year, month order by year, month\").toPandas()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(security_breaches[\"Date\"], security_breaches[\"count_of_security_breaches\"], linestyle = \":\", linewidth = 3, color = \"#db0f1d\", marker = \"*\", markeredgecolor = \"#000000\")\n",
    "plt.ylabel(\"Number of Security Breaches\", labelpad = 15)\n",
    "plt.xlabel(\"YEARS\", labelpad = 15)\n",
    "plt.title(\"Number of Security Breaches over the YEARS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delay of each carrier because of returning flights\n",
    "number_late_returns_delays = spark.sql(\"select carrier_name, cast(sum(late_aircraft_ct) as int) as number_of_late_returns, round(avg(late_aircraft_delay), 4) as average_delay_min from df where year >= 2021 group by carrier_name order by 2 desc, 3 desc\").toPandas()\n",
    "\n",
    "\n",
    "sns.lmplot(x = \"number_of_late_returns\", y = \"average_delay_min\", data = number_late_returns_delays, ci = 0.95, markers = 'x', line_kws={'color': 'red'})\n",
    "plt.ylabel(\"Average Delays in minutes\", labelpad = 15)\n",
    "plt.xlabel(\"Number of Late returns\", labelpad = 15)\n",
    "plt.title(\"Scatter Plot\")\n",
    "plt.xticks(range(0, 11000, 1000))\n",
    "plt.show()\n",
    "print(number_late_returns_delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delayed pie chart\n",
    "delayed_reasons = spark.sql(\"select sum(carrier_ct), sum(weather_ct), sum(nas_ct), sum(late_aircraft_ct), sum(security_ct) from df\").toPandas()\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "labels = [\"Carrier (staff issues)\", \"Weather\", \"Air traffic\", \"Aircrafts late arrival\", \"security\"]\n",
    "plt.pie(delayed_reasons.values.tolist()[0], labels = labels, autopct = '%1.1f%%',\n",
    "        wedgeprops = {\"edgecolor\" : \"black\",\n",
    "                      'linewidth': 1,\n",
    "                      'antialiased': True})\n",
    "\n",
    "plt.title(\"Percentage of Reasons Delay\")\n",
    "plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diverted airports\n",
    "diverted_df = spark.sql(\"select airport_name, cast(sum(arr_diverted)/12 as int) as average_monthly_diverted from df where year >= 2021 group by airport_name order by sum(arr_diverted)/12 desc\").toPandas()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.hist(diverted_df[\"average_monthly_diverted\"], bins=[0,1,2,3,4,5,6,7], edgecolor = \"#000000\", color = \"#008080\")\n",
    "plt.ylabel(\"Number of Airports\", labelpad = 15)\n",
    "plt.xlabel(\"Number of Diversions from the Airport\", labelpad = 15)\n",
    "plt.title(\"Histogram for Number of Airport for Diversions occured\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delay due to carrier issues\n",
    "carrier_delay = spark.sql(\"select carrier_name, cast(sum(carrier_ct)/12 as int) as monthly_number_of_delays from df where year >= 2021 group by carrier_name order by sum(carrier_ct)/12 desc\").toPandas()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.barplot(x = carrier_delay['carrier_name'], y = carrier_delay['monthly_number_of_delays'], edgecolor = \"#000000\", palette='Blues_r')\n",
    "plt.xlabel(\"Carrier\", labelpad = 15)\n",
    "plt.ylabel(\"Monthly Delays due to Carrier Issues\", labelpad = 15)\n",
    "plt.title(\"Monthly Delays because of Airline Issues\")\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Classification to Predict Number of delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatrix = df[list_of_numerical_columns].toPandas().corr().loc['arr_delay'].to_frame()\n",
    "sns.heatmap(corrMatrix, square=True, cmap='Blues')\n",
    "\n",
    "correlation_columns = [i for i in corrMatrix.index if(corrMatrix.loc[i][0] >= 0.5)]\n",
    "correlation_columns.remove('arr_delay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols = correlation_columns, outputCol = 'features')\n",
    "lr_df = assembler.transform(df)\n",
    "\n",
    "lr_df = lr_df.select('features', 'arr_delay')\n",
    "lr_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = lr_df.randomSplit([0.75, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnr = LinearRegression(featuresCol='features', labelCol='arr_delay')\n",
    "\n",
    "model = lnr.fit(train_df)\n",
    "results = model.evaluate(train_df)\n",
    "\n",
    "print('R Squared Error :', results.r2)\n",
    "print('Mean Squared Error :', results.meanSquaredError)\n",
    "print('Mean Absolute Error :', results.meanAbsoluteError)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.hist(results.residuals.toPandas(), bins=range(-400, 400, 25), edgecolor = \"#000000\", color = \"#00ffae\")\n",
    "plt.ylabel(\"Number of Occurances\", labelpad = 15)\n",
    "plt.xlabel(\"Range of values\", labelpad = 15)\n",
    "plt.title(\"Plotted Residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test_df.select('features')).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "plt.hist(test_df.toPandas()[\"arr_delay\"], bins = range(0, 5000, 250), edgecolor = \"#000000\", color = \"#213adb\")\n",
    "plt.hist(predictions[\"prediction\"], bins = range(0, 5000, 250), edgecolor = \"#000000\", color = \"#ff0044\", alpha = 0.5)\n",
    "plt.legend([\"Test\", \"Predicted\"])\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Bins of Value\")\n",
    "plt.title(\"Test VS Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering to predict Type of Busy Airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = df.select(\"busy_type\").distinct().count()\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatrix = df.toPandas().corr().loc['busy_type'].to_frame()\n",
    "sns.heatmap(corrMatrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_columns = [i for i in corrMatrix.index if(corrMatrix.loc[i][0] >= 0.15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols = correlation_columns, outputCol = \"features\")\n",
    "kmeans_df = assembler.transform(df)\n",
    "\n",
    "kmeans = KMeans(featuresCol = 'features', k = k, maxIter = 100)\n",
    "model = kmeans.fit(kmeans_df)\n",
    "predictions = model.transform(kmeans_df)\n",
    "predictions = predictions.select(\"busy_type\", \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(predictions.select(\"busy_type\").collect(), predictions.select(\"prediction\").collect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = predictions.groupBy(\"busy_type\", \"prediction\").count().orderBy(\"busy_type\", \"prediction\").toPandas()\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = predictions_df.groupby(['busy_type', 'prediction']).agg({'count': 'sum'})\n",
    "predictions_df = predictions_df.groupby(level=0).apply(lambda x:100 * x / float(x.sum()))\n",
    "predictions_df.rename(columns = {'count':'percentage'}, inplace = True)\n",
    "\n",
    "plt.figure(figsize = (15,5))\n",
    "predictions_df.unstack().plot(kind='bar', edgecolor = \"#000000\", stacked=True)\n",
    "plt.xlabel(\"Original Values\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.title(\"% of predicted values\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), labels = [\"0% occurance\", \"1% occurance\", \"2% occurance\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic Regression for predicting Security Issues Reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('security_issue', F.when(F.col(\"security_ct\") > 0, 1).when(F.col(\"security_ct\") == 0, 0).otherwise(-1))\n",
    "df.groupby(\"security_issue\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatrix = df.toPandas().corr().loc[\"security_issue\"].to_frame()\n",
    "sns.heatmap(corrMatrix, annot=True, cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_columns = [i for i in corrMatrix.index if(corrMatrix.loc[i][0] >= 0.1)]\n",
    "correlation_columns.remove(\"security_issue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols = correlation_columns, outputCol = \"features\")\n",
    "\n",
    "log_df = assembler.transform(df)\n",
    "log_df = log_df.select(\"features\", \"security_issue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = log_df.randomSplit([0.75,0.25])\n",
    "\n",
    "model = LogisticRegression(labelCol = \"security_issue\").fit(train_df)\n",
    "\n",
    "train_results = model.evaluate(train_df).predictions\n",
    "train_results.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(train_results.select(\"security_issue\").collect(), train_results.select(\"prediction\").collect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing on test data\n",
    "results = model.evaluate(test_df).predictions\n",
    "results.groupby(\"security_issue\", \"prediction\").agg({'prediction':'count'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•\tThe number of average Delays before the covid pandemic decreased steadily over the years but has seen a sharp increase after that period.\n",
    "•\tAlmost all the airlines saw a sharp increase in the number of cancelled flights during the covid pandemic season.\n",
    "•\tCarrier issues like staff not being available accounted for at least 40% of the total delays in 2021.\n",
    "•\tThe number of security breaches over the years has reduced sharply.\n",
    "•\tOctober and November are the months with the most scheduled flights.\n",
    "•\tSkywest Airlines has the highest average monthly delay and the most cancelled flights for the year 2021.\n",
    "•\tThe number of diversions to other airports is minimal and has not increased over the years.\n",
    "•\tThere is a high correlation between a delayed flight and the delays occurring due to Airline issues.\n",
    "•\tCold Bay Airport, Alaska, has the highest number of breaches compared to the number of flights arriving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
